{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLi9_3cumfU3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already up-to-date: spacy in /opt/conda/lib/python3.7/site-packages (2.2.4)\r\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (7.4.0)\r\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.46.1)\r\nRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (41.0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.0)\r\nRequirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.2)\r\nRequirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.18.5)\r\nRequirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.4.1)\r\nRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.2)\r\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.6.0)\r\nRequirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.9.6)\r\nRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.3)\r\nRequirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.21.0)\r\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\r\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\r\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.2)\r\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\r\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\r\nRequirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\r\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /opt/conda/lib/python3.7/site-packages (2.2.5)\r\nRequirement already satisfied: spacy>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\r\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.46.1)\r\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\r\nRequirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.6)\r\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\r\nRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\r\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\r\nRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\r\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.0)\r\nRequirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.1)\r\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\r\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.2)\r\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\r\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\nYou can now load the model via spacy.load('en_core_web_sm')\r\n\u001b[38;5;2m✔ Linking successful\u001b[0m\r\n/opt/conda/lib/python3.7/site-packages/en_core_web_sm -->\r\n/opt/conda/lib/python3.7/site-packages/spacy/data/en\r\nYou can now load the model via spacy.load('en')\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "!pip install spacy --upgrade\n",
    "!python -m spacy download en\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdGi9h9wmjYF",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def customize_stop_words(nlp):\n",
    "  token_exception_list = ['by', 'per', 'how', 'many', 'much', 'and', 'most', 'more', 'than', 'hundred']    \n",
    "  for token in token_exception_list:\n",
    "    if nlp.vocab[token].is_stop:\n",
    "      nlp.vocab[token].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsMZrEP4074V",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "def customize_displacy(doc):\n",
    "  displacy.render(doc, style='dep', jupyter=True, options={'distance': 90, 'fine_grained' : True, 'add_lemma' : True, 'collapse_phrases' : False})\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "dxV1pa590_LR",
    "outputId": "c85fa86e-dfa3-47bc-c852-8b3d6f22e653",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advmod\n",
      "amod\n",
      "compound\n",
      "nsubj\n",
      "aux\n",
      "ROOT\n",
      "punct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8144d7a805384b3d9f5229213eae4c23-0\" class=\"displacy\" width=\"590\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">How</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"50\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">WRB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">many</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"140\">many</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">JJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">oil</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"230\">oil</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">NN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">fields</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"320\">field</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NNS</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">do</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"410\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VBP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">exist?</tspan>\n",
       "    <tspan class=\"displacy-lemma\" dy=\"2em\" fill=\"currentColor\" x=\"500\">exist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8144d7a805384b3d9f5229213eae4c23-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,47.0 135.0,47.0 135.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8144d7a805384b3d9f5229213eae4c23-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8144d7a805384b3d9f5229213eae4c23-0-1\" stroke-width=\"2px\" d=\"M160,92.0 C160,2.0 320.0,2.0 320.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8144d7a805384b3d9f5229213eae4c23-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,94.0 L152,82.0 168,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8144d7a805384b3d9f5229213eae4c23-0-2\" stroke-width=\"2px\" d=\"M250,92.0 C250,47.0 315.0,47.0 315.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8144d7a805384b3d9f5229213eae4c23-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,94.0 L242,82.0 258,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8144d7a805384b3d9f5229213eae4c23-0-3\" stroke-width=\"2px\" d=\"M340,92.0 C340,2.0 500.0,2.0 500.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8144d7a805384b3d9f5229213eae4c23-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,94.0 L332,82.0 348,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8144d7a805384b3d9f5229213eae4c23-0-4\" stroke-width=\"2px\" d=\"M430,92.0 C430,47.0 495.0,47.0 495.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8144d7a805384b3d9f5229213eae4c23-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,94.0 L422,82.0 438,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('How many oil fields do exist?')\n",
    "for token in doc:\n",
    "  print(token.dep_)\n",
    "customize_displacy(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOw-FwqCyYFb",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-169883f7a186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.1.1\\\\helpers\\\\pydev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.1.1\\\\helpers-pro\\\\jupyter_debug'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydev_jupyter_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpydev_jupyter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach_to_debugger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m52861\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydev_jupyter_utils'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydev_jupyter_utils'",
     "output_type": "error"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "class Glamorise:\n",
    "\n",
    "  # instance attribute\n",
    "  def __init__(self, txt, lang = \"en\"):\n",
    "    self.__nlp = spacy.load(lang)\n",
    "    self.__doc = self.__nlp(txt)\n",
    "    self.__customize_stop_words\n",
    "    self.__aggregate_function = ''\n",
    "    self.__aggregate_field = ''\n",
    "    self.__group_by_field = ''\n",
    "    self.__having_field = ''\n",
    "    self.__cut_text = []\n",
    "    self.__group_by = False\n",
    "    self.__having = ''\n",
    "    self.__matcher = Matcher(self.__nlp.vocab)\n",
    "\n",
    "  @property\n",
    "  def aggregate_function(self):\n",
    "    return self.__aggregate_function\n",
    "  \n",
    "  @property\n",
    "  def aggregate_field(self):\n",
    "    return self.__aggregate_field\n",
    "  \n",
    "  @property\n",
    "  def group_by_field(self):\n",
    "    return self.__group_by_field\n",
    "\n",
    "  @property\n",
    "  def having_field(self):\n",
    "    return self.__having_field\n",
    "  @property\n",
    "  def cut_text(self):\n",
    "    return self.__cut_text\n",
    "\n",
    "  @property\n",
    "  def group_by(self):\n",
    "    return self.__group_by\n",
    "\n",
    "  @property\n",
    "  def having(self):\n",
    "    return self.__having\n",
    "    \n",
    "  def __customize_stop_words(self):\n",
    "    token_exception_list = ['by', 'per', 'how', 'many', 'much', 'and', 'more', 'greater', 'than', 'hundred', 'of']    \n",
    "    for token in token_exception_list:\n",
    "      if self.__nlp.vocab[token].is_stop:\n",
    "        self.__nlp.vocab[token].is_stop = False      \n",
    "  \n",
    "  def matcher(self, patterns):        \n",
    "    for pattern in patterns:      \n",
    "      self.__matcher.add(str(patterns), None, pattern)    \n",
    "      matches = self.__matcher(self.__doc)\n",
    "      if matches != []:\n",
    "        return True \n",
    "    return False\n",
    "      \n",
    "\n",
    "  def build_field(self, token, type):    \n",
    "    print(\"token.ancestors\", str(token.ancestors))\n",
    "    for ancestor in token.ancestors:            \n",
    "      # set the field\n",
    "      field = ancestor.lemma_        \n",
    "      accum = ''                  \n",
    "      #look for compund terms\n",
    "      for ancestor_children in ancestor.subtree:                                          \n",
    "        # get compound terms that are not proper noun\n",
    "        if ancestor_children.dep_ == 'compound' and ancestor_children.tag_ != 'NNP':                \n",
    "          accum = accum + ancestor_children.lemma_ + ' '                         \n",
    "      field = accum + field          \n",
    "      if type == 'aggregate':\n",
    "        self.__aggregate_field = field\n",
    "      if type == 'group by':\n",
    "        self.__group_by_field = field\n",
    "      if type == 'having':        \n",
    "        self.__having_field = field\n",
    "      break\n",
    "    \n",
    "  '''\n",
    "  def pattern_match(self, token, reserved_words, children_reserved_words = None, ancestors_reserved_words = None): \n",
    "    if token.lemma_ in reserved_words:              \n",
    "        if children_reserved_words is None and ancestors_reserved_words is None:\n",
    "          print(\"reserved_words\")\n",
    "          return True\n",
    "        children = list(token.children)\n",
    "        print(\"children\")\n",
    "        for child in children:                \n",
    "          if child.lemma_ in children_reserved_words:       \n",
    "            if ancestors_reserved_words is None:\n",
    "              return True\n",
    "            else:\n",
    "              break  \n",
    "        ancestors = list(token.ancestors)\n",
    "        print(\"parent\")\n",
    "        for ancestor in ancestors:                \n",
    "          if ancestor.lemma_ in ancestor_reserved_words:                   \n",
    "            return True\n",
    "    return False\n",
    "  '''\n",
    "  def pattern_match(self, token, reserved_words, children_reserved_words = None, group_by = False, having = ''):     \n",
    "    if token.lemma_ in reserved_words:      \n",
    "      if reserved_words[token.lemma_] is not None:\n",
    "        self.__aggregate_function = reserved_words[token.lemma_]      \n",
    "      self.__group_by = group_by\n",
    "      self.__having = having\n",
    "      if not group_by and having == '':\n",
    "        self.build_field(token, type = 'aggregate')\n",
    "      elif group_by:\n",
    "        self.build_field(token, type = 'group by')\n",
    "      elif having != '':\n",
    "        self.build_field(token, type = 'having')\n",
    "      if children_reserved_words is None:                \n",
    "        self.__cut_text.append(token.lemma_)\n",
    "      else:  \n",
    "        children = list(token.children)        \n",
    "        for child in children:             \n",
    "          if child.lemma_ in children_reserved_words:                                         \n",
    "            self.__cut_text.append(child.lemma_ + ' ' + token.lemma_)\n",
    "          \n",
    "          \n",
    "      \n",
    "\n",
    "  def pattern_scan(self):     \n",
    "    for token in self.__doc:        \n",
    "      '''\n",
    "      # get the how many, how much pattern\n",
    "      if token.lemma_ in ['many', 'much']:      \n",
    "        children = list(token.children)      \n",
    "        for child in children:                \n",
    "          if child.lemma_ == 'how':       \n",
    "            #set aggregate_function\n",
    "            if token.lemma_ == 'many':\n",
    "              self.__aggregate_function = 'count'  \n",
    "            elif  token.lemma_ == 'much':\n",
    "              self.__aggregate_function = 'sum'           \n",
    "            #set the text that will be removed from the query before passing to the NLIDB\n",
    "            self.__cut_text = child.lemma_ + ' ' + token.lemma_          \n",
    "            self.build_aggregate_field(token)\n",
    "      '''      \n",
    "      # get the how many, how much pattern\n",
    "      self.pattern_match(token, {'many' : 'count', 'number' : 'count', 'much' : 'sum'}, ['how', 'of'])       \n",
    "\n",
    "      # get the most, maximum, max pattern\n",
    "      self.pattern_match(token, {'most' : 'max', 'maximum' : 'max', 'max' : 'max'})  \n",
    "\n",
    "      # get the least, minimum, min pattern\n",
    "      self.pattern_match(token, {'least': 'min', 'minimum' : 'min', 'min' : 'min'})\n",
    "\n",
    "      # get the average, mean pattern\n",
    "      self.pattern_match(token, {'average' : 'avg', 'mean' : 'avg', 'avg' : 'avg'})\n",
    "\n",
    "      # get the by, per pattern\n",
    "      self.pattern_match(token, {'by' : None , 'per' : None}, group_by = True)     \n",
    "\n",
    "      # get the greater than, more than pattern\n",
    "      self.pattern_match(token, {'great' : None, 'more' : None}, having = '+') \n",
    "\n",
    "      # get the less than pattern\n",
    "      self.pattern_match(token, {'less' : None}, having = '-') \n",
    "\n",
    "      # get the equal to pattern\n",
    "      self.pattern_match(token, {'equal' : None}, having = '=') \n",
    "  \n",
    "  def customized_displacy(self):\n",
    "    displacy.render(self.__doc, style='dep', jupyter=True, options={'distance': 90, 'fine_grained' : True, 'add_lemma' : True, 'collapse_phrases' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xgprf8h22SLv",
    "outputId": "996c2acf-4b62-4931-c353-87c775c8eac0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9ba3bef17280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.1.1\\\\helpers\\\\pydev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2019.1.1\\\\helpers-pro\\\\jupyter_debug'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydev_jupyter_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpydev_jupyter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach_to_debugger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m52921\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydev_jupyter_utils'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydev_jupyter_utils'",
     "output_type": "error"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('./datasets/teste.csv') as csv_file:\n",
    "#with open('/content/sample_data/teste.csv') as csv_file:\n",
    "  csv_reader = csv.reader(csv_file, delimiter=',', quotechar=\"'\")\n",
    "  line_count = 0\n",
    "  for row in csv_reader:    \n",
    "    nl_query = row[0]\n",
    "    print(\"\\n\\nNatural Language Query: \",nl_query )\n",
    "    glamorise = Glamorise(nl_query)\n",
    "    glamorise.pattern_scan()\n",
    "    glamorise.customized_displacy()\n",
    "    print(\"aggregate function: \", glamorise.aggregate_function)\n",
    "    print(\"aggregate field: \", glamorise.aggregate_field)\n",
    "    print(\"group_by_field: \", glamorise.group_by_field)\n",
    "    print(\"having_field: \", glamorise.having_field)\n",
    "    print(\"group_by: \", glamorise.group_by)\n",
    "    print(\"having: \", glamorise.having)\n",
    "    print(\"cut_text: \", glamorise.cut_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgM8DOtscayK"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dq9DWwbtpQpi"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "47EoL02eiW3P",
    "outputId": "843601c1-7029-486c-a2ef-b49f77b2bdf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = {'a': 1, 'b' : 2,'c': 5}\n",
    "'a' in myList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "B6gH4jgdOmnt",
    "outputId": "70a414f2-05d9-45b3-bf44-f2d6979b2c7b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-13d4d93621d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    " \n",
    "# Just to make it a bit more readable\n",
    "WN_NOUN = 'n'\n",
    "WN_VERB = 'v'\n",
    "WN_ADJECTIVE = 'a'\n",
    "WN_ADJECTIVE_SATELLITE = 's'\n",
    "WN_ADVERB = 'r'\n",
    " \n",
    "def convert(word, from_pos, to_pos):    \n",
    "    \"\"\" Transform words given from/to POS tags \"\"\"\n",
    " \n",
    "    synsets = wn.synsets(word, pos=from_pos)\n",
    "    print(synsets)\n",
    " \n",
    "    # Word not found\n",
    "    if not synsets:\n",
    "        return []\n",
    "    \n",
    "    # Get all lemmas of the word (consider 'a'and 's' equivalent)\n",
    "    lemmas = [l for s in synsets\n",
    "                for l in s.lemmas()\n",
    "                if s.name().split('.')[1] == from_pos\n",
    "                    or from_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "                        and s.name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]\n",
    "    print(\"lemmas\",lemmas)\n",
    "    # Get related forms\n",
    "    derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "    print(\"derivationally_related_forms\",derivationally_related_forms)\n",
    "    # return derivationally_related_forms\n",
    "    # filter only the desired pos (consider 'a' and 's' equivalent)\n",
    "    related_noun_lemmas = [l for drf in derivationally_related_forms\n",
    "                             for l in drf[1] \n",
    "                             if l.synset().name().split('.')[1] == to_pos\n",
    "                                or to_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "                                    and l.synset().name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]\n",
    " \n",
    "    # Extract the words from the lemmas\n",
    "    words = [l.name() for l in related_noun_lemmas]    \n",
    "    len_words = len(words)\n",
    " \n",
    "    # Build the result in the form of a list containing tuples (word, probability)\n",
    "    result = [(w, float(words.count(w))/len_words) for w in set(words)]\n",
    "    result.sort(key=lambda w: -w[1])\n",
    " \n",
    "    # return all the possibilities sorted by probability\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "KuQO5-yHbgnS",
    "outputId": "d296cff1-d6e7-47aa-fef5-403fb5d4488e"
   },
   "outputs": [],
   "source": [
    "print(convert(\"productive\", WN_ADJECTIVE, WN_NOUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "MHpEVzQYbrEr",
    "outputId": "e1005b97-4e9e-4b6b-d855-7a0b75bccede"
   },
   "outputs": [],
   "source": [
    "synsets = wn.synsets('productive', 'a')\n",
    "from_pos = 'a'\n",
    "# Get all lemmas of the word (consider 'a'and 's' equivalent)\n",
    "lemmas = [l for s in synsets\n",
    "            for l in s.lemmas()\n",
    "            if s.name().split('.')[1] == from_pos\n",
    "                or from_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "                    and s.name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]\n",
    "\n",
    "# Get related forms\n",
    "derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "\n",
    "# filter only the desired pos (consider 'a' and 's' equivalent)\n",
    "for drf in derivationally_related_forms:\n",
    "  for l in drf[1]:\n",
    "    print(l)\n",
    "            #              if l.synset().name().split('.')[1] == to_pos\n",
    "            #                or to_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "              #                   and l.synset().name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEXcO7eCnH8V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PFP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-2382f789",
   "language": "python",
   "display_name": "PyCharm (GLAMORISE)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}